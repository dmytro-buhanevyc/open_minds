{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    " from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    " import os\n",
    "os.getcwd()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11284dde",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af97ba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#read csv as df\n",
    "df = pd.read_csv('/Users/dimabuhanevyc/Documents/OpenMinds/test_assignment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df103b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585b8bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c3937",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0  \n",
    "\n",
    " def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"error\"  \n",
    "\n",
    " df['language'] = df['fullText'].progress_apply(detect_language)\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35110c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df1552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d66bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.fromisoformat('2019-12-04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43062207",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['pubTime']).dt.date\n",
    "df.Date.min()\n",
    "df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6ef5d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "\n",
    " stop_words = nlp.Defaults.stop_words\n",
    "\n",
    " def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "     preprocessed_text = ' '.join([token.lemma_.lower() for token in doc if not token.is_punct and not token.is_space and token.text.lower() not in stop_words])\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['fullText'].progress_apply(preprocess_text)\n",
    "\n",
    " import os\n",
    " os.getcwd()\n",
    "\n",
    " df.to_json('om_test_processedtext.json', orient='records', lines=True)\n",
    "\n",
    " df = pd.read_json('om_test_processedtext.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f909b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147099b2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5674d2e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_name = \"DeepPavlov/rubert-base-cased\"   \n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for text in tqdm(df['processed_text'].tolist(), desc=\"Generating embeddings\"):\n",
    "    embedding = model.encode(text, show_progress_bar=False)\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embeddings as json\n",
    "embeddings_list = [embedding.tolist() for embedding in embeddings]\n",
    "\n",
    " with open('embeddings.json', 'w') as f:\n",
    "    json.dump(embeddings_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905eb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64af61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    " with open('embeddings.json', 'r') as f:\n",
    "    embeddings_list = json.load(f)\n",
    "\n",
    " embeddings = np.array(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee1c3e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "date_min = df.Date.min()\n",
    "date_max = df.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "# Initialize and fit BERTopic\n",
    "topic_model = BERTopic(language=None, calculate_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['processed_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771cfc3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e9f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_hierarchy()\n",
    "fig.update_layout(width=600, height=1000)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036ac11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72e267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac39afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592081fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = topic_model.get_topic_tree(hierarchical_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf55d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree)\n",
    "\n",
    " topic_model.visualize_barchart(top_n_topics=11, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ae9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a5afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3133e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394365e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ad38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf60c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278f7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386dcbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    " for index, row in topic_info.iterrows():\n",
    "    if row['Topic'] != -1:  # -1 is noise\n",
    "        topic_num = row['Topic']\n",
    "        print(f\"\\nTopic: {topic_num}\")\n",
    "        print(f\"Size: {row['Count']}\")\n",
    "\n",
    "         words_scores = topic_model.get_topic(topic_num)  # c-TF-IDF scores\n",
    "\n",
    "         top_n_words = words_scores[:10]  \n",
    "        top_words = [word for word, score in top_n_words]\n",
    "        print(f\"Top words: {top_words}\")\n",
    "\n",
    "\n",
    "\n",
    " largest_topics = topic_info.sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560f67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78fd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249a143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fa336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b42828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d60bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318cc871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736af7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b2a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08b790c0",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adc012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87919bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843577",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min_formatted = date_min.strftime('%A, %b, %d')\n",
    "date_max_formatted = date_max.strftime('%A, %b, %d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc16901",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model_2d = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine', random_state=42)\n",
    "reduced_embeddings_2d = umap_model_2d.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_coordinate'] = reduced_embeddings_2d[:, 0]\n",
    "df['y_coordinate'] = reduced_embeddings_2d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7652b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_labels_2d'] = cluster_labels_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_2d = len(set(cluster_labels_2d)) - (1 if -1 in cluster_labels_2d else 0)\n",
    "n_noise_2d = list(cluster_labels_2d).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of clusters found: {n_clusters_2d}\")\n",
    "print(f\"Number of noise points: {n_noise_2d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f762276",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477beb1e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "df['cluster_count'] = df.groupby('cluster_labels_2d')['cluster_labels_2d'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22158160",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def wrap_text(text):\n",
    "    return \"<br>\".join(textwrap.wrap(text, width=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a91891",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#replace <br> with \\n\n",
    "df['fullText'] = df['fullText'].str.replace('<br>', '')\n",
    "# Generate hover text with cluster information, full text, and post counts\n",
    "hover_texts_2d = df.apply(lambda row: f\"Cluster: {row['cluster_labels_2d']}<br>Posts in Cluster: {row['cluster_count']}<br>Full Text: {wrap_text(row['fullText'])}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f089b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2D scatter plot\n",
    "fig_2d = px.scatter(\n",
    "    df, x=reduced_embeddings_2d[:, 0], y=reduced_embeddings_2d[:, 1],\n",
    "    color=\"cluster_labels_2d\",  # Ensure this uses the updated 2D cluster labels\n",
    "    hover_data=[hover_texts_2d],\n",
    "    title=f\"<b>Topic Modeling and Clustering Analysis</b><br>Between {date_min_formatted} and {date_max_formatted}\",\n",
    "    labels={\"hover_data_0\": \"Details\"}  # Rename hover data label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the layout to include an annotation for clusters and Greek values, and remove legend\n",
    "fig_2d.update_layout(\n",
    "    annotations=[{\n",
    "        'text': f\"Clusters (Κ): {n_clusters_2d}<br>Noise Points (η): {n_noise_2d}<br>Clustering Params: Min Cluster Size (Ν) = 20, Min Samples (Σ) = 1\",\n",
    "        'showarrow': False,\n",
    "        'x': 1,\n",
    "        'xref': \"paper\",\n",
    "        'xanchor': 'right',\n",
    "        'xshift': 0,\n",
    "        'y': 1,\n",
    "        'yref': \"paper\",\n",
    "        'yanchor': 'top',\n",
    "        'align': \"right\",\n",
    "        'font': {\n",
    "            'size': 10  # Make font even smaller\n",
    "        }\n",
    "    }],\n",
    "    showlegend=False\n",
    ")\n",
    "#delete colorbar\n",
    "fig_2d.update_coloraxes(colorbar_title=None)\n",
    "#make markers smaller\n",
    "fig_2d.update_traces(marker=dict(size=3))\n",
    "#make background white\n",
    "fig_2d.update_layout(plot_bgcolor='white')\n",
    "#make bigger\n",
    "fig_2d.update_layout(width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a41a4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#remove colorbar\n",
    "fig_2d.update_layout(coloraxis_showscale=False)\n",
    "# Display the figure\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Plotly figure as an HTML file\n",
    "fig_2d.write_html(\"/Users/dimabuhanevyc/Documents/Research_Analysis/RandomResearch/openminds/visualization.html\", include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ccbfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9918339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46dc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group the DataFrame by cluster labels\n",
    "clustered_groups = df.groupby('cluster_labels_2d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store central text and top words per cluster\n",
    "central_texts = []\n",
    "top_words_per_cluster = []\n",
    "# Iterate over each cluster\n",
    "for cluster_label, cluster_data in clustered_groups:\n",
    "    # Calculate centroid of the cluster\n",
    "    centroid = cluster_data[['x_coordinate', 'y_coordinate']].mean(axis=0).values.reshape(1, -1)\n",
    "    \n",
    "    # Calculate Euclidean distances between each point in the cluster and the centroid\n",
    "    distances = euclidean_distances(cluster_data[['x_coordinate', 'y_coordinate']], centroid)\n",
    "    \n",
    "    # Find the index of the point with the smallest distance (i.e., the central text)\n",
    "    central_text_index = distances.argmin()\n",
    "    \n",
    "    # Append the central text to the list\n",
    "    central_texts.append(cluster_data.iloc[central_text_index]['fullText'])\n",
    "    \n",
    "    # Get all text data in the cluster\n",
    "    texts_in_cluster = cluster_data['processed_text']  # Using processed_text for counting top words\n",
    "    \n",
    "    # Tokenize and count words in the cluster\n",
    "    all_words = ' '.join(texts_in_cluster).split()\n",
    "    word_counts = Counter(all_words)\n",
    "    \n",
    "    # Select the top 10 words based on their frequency\n",
    "    top_words = word_counts.most_common(10)\n",
    "    \n",
    "    # Append the top words to the list\n",
    "    top_words_per_cluster.append(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830c0f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Print central texts and top words per cluster\n",
    "for i, (central_text, top_words) in enumerate(zip(central_texts, top_words_per_cluster)):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    print(\"Central Text:\", central_text)\n",
    "    print(\"Top 10 Words:\", top_words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dbae88",
   "metadata": {},
   "source": [
    "Calculate top words and central texts per cluster (assuming you've already run the code for this)\n",
    "Code for calculating top words and central texts per cluster goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hover text with cluster information, central text, top 10 words, and post counts\n",
    "hover_texts_2d = df.apply(lambda row: f\"Cluster: {row['cluster_labels_2d']}<br>Top 10 Words: {' '.join([word for word, _ in top_words_per_cluster[row['cluster_labels_2d']]])}<br>Central Text: {wrap_text(central_texts[row['cluster_labels_2d']])}\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 2D scatter plot\n",
    "fig_2d = px.scatter(\n",
    "    df, x=reduced_embeddings_2d[:, 0], y=reduced_embeddings_2d[:, 1],\n",
    "    color=\"cluster_labels_2d\",  # Ensure this uses the updated 2D cluster labels\n",
    "    hover_data=[hover_texts_2d],\n",
    "    title=f\"<b>Topic Modeling and Clustering Analysis</b><br>Between {date_min_formatted} and {date_max_formatted}\",\n",
    "    labels={\"hover_data_0\": \"Details\"}  # Rename hover data label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae205a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the layout to include an annotation for clusters and Greek values, and remove legend\n",
    "fig_2d.update_layout(\n",
    "    annotations=[{\n",
    "        'text': f\"Clusters (Κ): {n_clusters_2d}<br>Noise Points (η): {n_noise_2d}<br>Clustering Params: Min Cluster Size (Ν) = 20, Min Samples (Σ) = 1\",\n",
    "        'showarrow': False,\n",
    "        'x': 1,\n",
    "        'xref': \"paper\",\n",
    "        'xanchor': 'right',\n",
    "        'xshift': 0,\n",
    "        'y': 1,\n",
    "        'yref': \"paper\",\n",
    "        'yanchor': 'top',\n",
    "        'align': \"right\",\n",
    "        'font': {\n",
    "            'size': 10  # Make font even smaller\n",
    "        }\n",
    "    }],\n",
    "    showlegend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f16826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hover mode and add custom formatting\n",
    "fig_2d.update_traces(hovertemplate='%{customdata[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete colorbar\n",
    "fig_2d.update_coloraxes(colorbar_title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make markers smaller\n",
    "fig_2d.update_traces(marker=dict(size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make background white\n",
    "fig_2d.update_layout(plot_bgcolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure bigger\n",
    "fig_2d.update_layout(width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove colorbar\n",
    "fig_2d.update_layout(coloraxis_showscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the figure\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced54e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fa0754f",
   "metadata": {},
   "source": [
    "printing main clusters by count, excluding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2028a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = df[df['cluster_labels_2d'] != -1].groupby('cluster_labels_2d').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 10 clusters\n",
    "top_10_clusters = cluster_sizes.head(10).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f37beb",
   "metadata": {},
   "source": [
    "Assuming `date_min_formatted` and `date_max_formatted` are defined as before\n",
    "Assuming `df` is your DataFrame and `cluster_labels_2d` is the column with cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bc9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get the overall context and introduction\n",
    "print(f\"Between {date_min_formatted} and {date_max_formatted}, we have analyzed {len(df)} texts and identified {n_clusters_2d} clusters (excluding noise).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's mention the summary about the top 10 clusters and their central texts\n",
    "print(\"The top 10 clusters and their central texts are below:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd6529",
   "metadata": {},
   "source": [
    "Assuming `cluster_sizes` and `top_10_clusters` are defined as before\n",
    "Assuming `central_texts` is a dictionary or list indexed by cluster label as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_label in top_10_clusters:\n",
    "    # Get the cluster size\n",
    "    cluster_size = cluster_sizes[cluster_label]\n",
    "    \n",
    "    # Find the central text for this cluster\n",
    "    central_text = central_texts[cluster_label]  # Make sure central_texts is indexed correctly\n",
    "    \n",
    "    print(f\"Cluster Number: {cluster_label}, Count: {cluster_size}\")\n",
    "    print(f\"Central Text: {central_text}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentioning the graph\n",
    "print(\"The graph showing the total distribution of texts in our model is below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph\n",
    "# Assuming `fig_2d` is your Plotly figure for the graph\n",
    "fig_2d.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
